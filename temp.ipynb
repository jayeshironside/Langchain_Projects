{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from pandasai import PandasAI\n",
    "from pandasai.llm.openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.title(\"pandas-ai streamlit interface\")\n",
    "\n",
    "st.write(\"A demo interface for [PandasAI](https://github.com/gventuri/pandas-ai)\")\n",
    "st.write(\n",
    "    \"Looking for an example *.csv-file?, check [here](https://gist.github.com/netj/8836201).\"\n",
    ")\n",
    "\n",
    "if \"openai_key\" not in st.session_state:\n",
    "    with st.form(\"API key\"):\n",
    "        key = st.text_input(\"OpenAI Key\", value=\"\", type=\"password\")\n",
    "        if st.form_submit_button(\"Submit\"):\n",
    "            st.session_state.openai_key = key\n",
    "            st.session_state.prompt_history = []\n",
    "            st.session_state.df = None\n",
    "\n",
    "if \"openai_key\" in st.session_state:\n",
    "    if st.session_state.df is None:\n",
    "        uploaded_file = st.file_uploader(\"Choose a CSV file. This should be in long format (one datapoint per row).\",type=\"csv\")\n",
    "        if uploaded_file is not None:\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "            st.session_state.df = df\n",
    "\n",
    "    with st.form(\"Question\"):\n",
    "        question = st.text_input(\"Question\", value=\"\", type=\"default\")\n",
    "        submitted = st.form_submit_button(\"Submit\")\n",
    "        if submitted:\n",
    "            with st.spinner():\n",
    "                llm = OpenAI(api_token=st.session_state.openai_key)\n",
    "                pandas_ai = PandasAI(llm)\n",
    "                x = pandas_ai.run(st.session_state.df, prompt=question)\n",
    "\n",
    "                fig = plt.gcf()\n",
    "                if fig.get_axes():\n",
    "                    st.pyplot(fig)\n",
    "                st.write(x)\n",
    "                st.session_state.prompt_history.append(question)\n",
    "\n",
    "    if st.session_state.df is not None:\n",
    "        st.subheader(\"Current dataframe:\")\n",
    "        st.write(st.session_state.df)\n",
    "\n",
    "    st.subheader(\"Prompt history:\")\n",
    "    st.write(st.session_state.prompt_history)\n",
    "\n",
    "\n",
    "if st.button(\"Clear\"):\n",
    "    st.session_state.prompt_history = []\n",
    "    st.session_state.df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit designings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 21:35:02.039 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\jayesh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from streamlit_extras.colored_header import colored_header\n",
    "from streamlit_extras.add_vertical_space import add_vertical_space\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the Environment Variables. \n",
    "load_dotenv()\n",
    "st.set_page_config(page_title=\"OpenAssistant Powered Chat App\")\n",
    "\n",
    "# Sidebar contents\n",
    "with st.sidebar:\n",
    "    st.title('ü§óüí¨ HuggingChat App')\n",
    "    st.markdown('''\n",
    "    ## About\n",
    "    This app is an LLM-powered chatbot built using:\n",
    "    - [Streamlit](https://streamlit.io/)\n",
    "    - [LangChain](https://python.langchain.com/)\n",
    "    - [OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5](https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5) LLM model\n",
    "\n",
    "    ''')\n",
    "    add_vertical_space(3)\n",
    "    st.write('Made with ‚ù§Ô∏è by [Prompt Engineer](https://youtube.com/@engineerprompt)')\n",
    "\n",
    "st.header(\"Your Personal Assistant üí¨\")\n",
    "\n",
    "colored_header(label='', description='', color_name='blue-30')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
